from sklearn.naive_bayes import GaussianNB
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
import pandas as pd
import numpy as np

def train_and_evaluate_model(X_train, X_test, y_train, y_test, model_name, prep_name):
    """
    Trains a specified model (KNN or Naive Bayes) and evaluates it on the test set.
    Returns: A dictionary of results and the final training set's y_train.
    """
    print(f"\n--- Training {model_name} with {prep_name} ---")
    
    if model_name == 'KNN':
        model = KNeighborsClassifier(n_neighbors=5)
    elif model_name == 'NaiveBayes':
        model = GaussianNB()
    else:
        raise ValueError(f"Unknown model: {model_name}")

    # Ensure all data is numeric for NB and KNN and handle potential residual NaNs with a simple imputation (should be rare if previous steps are correct)
    X_train = X_train.select_dtypes(include=np.number).fillna(0)
    X_test = X_test.select_dtypes(include=np.number).fillna(0)
    
    # Align columns just in case a preparation step removed/added columns (e.g., Feature Selection)
    common_cols = list(set(X_train.columns) & set(X_test.columns))
    X_train = X_train[common_cols]
    X_test = X_test[common_cols]

    # Handle case where training data is empty (e.g., if outlier removal was too aggressive)
    if X_train.empty:
        accuracy = 0.0
        f1_score_avg = 0.0
        conf_matrix = np.array([[0,0],[0,0]])
    else:
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)
        
        accuracy = accuracy_score(y_test, y_pred)
        conf_matrix = confusion_matrix(y_test, y_pred)
        report = classification_report(y_test, y_pred, output_dict=True, zero_division=0)
        f1_score_avg = report['weighted avg']['f1-score']
    
    results = {
        'Preparation': prep_name,
        'Model': model_name,
        'Accuracy': accuracy,
        'F1_Score': f1_score_avg,
        'Confusion_Matrix': conf_matrix,
        'X_train_final': X_train,
        'X_test_final': X_test,
        'y_train_final': y_train # Store y_train as it may change size (outlier removal, balancing)
    }
    
    print(f"Accuracy: {accuracy:.4f} | F1-Score: {f1_score_avg:.4f}")
    
    return results

def compare_and_select_best(results_list):
    """
    Compares all results and selects the best performing dataset based on F1-Score.
    """
    df_results = pd.DataFrame([
        {'Preparation': r['Preparation'], 'Model': r['Model'], 'Accuracy': r['Accuracy'], 'F1_Score': r['F1_Score']} 
        for r in results_list
    ])
    
    # Find the row with the maximum F1-Score (this is the best model/approach combination)
    best_row = df_results.loc[df_results['F1_Score'].idxmax()]
    best_prep_name = best_row['Preparation']
    
    # Find the full results dictionary for the best preparation
    # We select the dataset generated by the approach that yielded the max F1-score
    best_result_dict = next(r for r in results_list if r['Preparation'].startswith(best_prep_name.split('_')[0]))

    print("\n\n####################################")
    print("BEST OVERALL PERFORMANCE:")
    print(best_row)
    print("####################################\n")

    return best_result_dict['X_train_final'], best_result_dict['X_test_final'], best_result_dict['y_train_final'], df_results